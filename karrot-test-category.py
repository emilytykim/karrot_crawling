import time, csv, os
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# â”€â”€â”€ 1) ë“œë¼ì´ë²„ ì„¸íŒ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
driver = uc.Chrome()
wait   = WebDriverWait(driver, 10)

# â”€â”€â”€ 2) â€œì†¡ë„ë™â€ í˜ì´ì§€ ì—´ê³  ì¹´í…Œê³ ë¦¬ë§Œ ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
driver.get("https://www.daangn.com/kr/buy-sell/?in=ì†¡ë„ë™-6543")
time.sleep(2)

cats = driver.find_elements(
    By.XPATH,
    "//h3[text()='ì¹´í…Œê³ ë¦¬']/following-sibling::div//a[@data-gtm='search_filter']"
)
categories = [(a.find_element(By.TAG_NAME,"span").text.strip(),
               a.get_attribute("href")) for a in cats]
print("â–¶ ì¹´í…Œê³ ë¦¬ ì¸ì‹:", [c[0] for c in categories])

# â”€â”€â”€ 3) ì¹´í…Œê³ ë¦¬ë³„ í…ŒìŠ¤íŠ¸ ìˆœíšŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
for cat_name, cat_url in categories:
    safe = cat_name.replace("/", "_")
    fn   = f"daangn_ì†¡ë„ë™_{safe}.csv"
    print(f"\nâ–¶ [{cat_name}] í…ŒìŠ¤íŠ¸ ì‹œì‘ â†’ {fn}")

    with open(fn, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow(["ì¹´í…Œê³ ë¦¬","ìƒí’ˆëª…","ê°€ê²©","ë‹‰ë„¤ì„","ì‘ì„±ì¼ì","URL"])
        f.flush()

        driver.get(cat_url)
        time.sleep(2)

        # (2) ìŠ¤í¬ë¡¤ + ë”ë³´ê¸° (ìµœëŒ€ 5íšŒ)
        for _ in range(5):
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1)
            try:
                btn = wait.until(EC.element_to_be_clickable(
                    (By.XPATH, "//button[contains(text(),'ë”ë³´ê¸°')]")
                ))
                btn.click()
                time.sleep(1)
            except:
                break

        # (3) ìµœëŒ€ 5ê°œ ìƒí’ˆ ë§í¬ë§Œ
        anchors = driver.find_elements(By.CSS_SELECTOR, 'a[data-gtm="search_article"]')
        urls = []
        for a in anchors:
            href = a.get_attribute("href")
            if href and "/kr/buy-sell/" in href and href not in urls:
                urls.append(href)
            if len(urls) >= 5:
                break
        print(f"   â–¶ [{cat_name}] 5ê°œ ë§í¬ ìˆ˜ì§‘ ì™„ë£Œ")

        # (4) ìƒì„¸ í¬ë¡¤ë§ + ì¦‰ì‹œ ì €ì¥
        for idx, url in enumerate(urls, 1):
            driver.get(url)
            time.sleep(1)
            def get_text(sel):
                try:    return driver.find_element(By.CSS_SELECTOR, sel).text
                except: return "N/A"

            title    = get_text("h1.sprinkles_display_inline_base__1byufe82a")
            price    = get_text("h3.jy3q4ib.sprinkles_fontWeight_bold__1byufe81z")
            nickname = get_text("span._1mr23zje")
            date     = get_text("time")

            writer.writerow([cat_name, title, price, nickname, date, url])
            f.flush()
            print(f"     {idx}/5 í¬ë¡¤ë§: {title}")

    print(f"âœ… [{cat_name}] í…ŒìŠ¤íŠ¸ CSV ìƒì„±ë¨ â†’ {os.path.abspath(fn)}")

driver.quit()
print("\nğŸ‰ ì¹´í…Œê³ ë¦¬ ìˆœíšŒ + 5ê°œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
