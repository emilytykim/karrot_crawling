import json, os, csv, time
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
import urllib.parse
import re
from multiprocessing import Pool, cpu_count, Manager
import math
from datetime import datetime

# â”€â”€â”€ ìºì‹œëœ JSON ì½ê¸° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# with open("regions_gangnam.json","r",encoding="utf-8") as f:
#     regions = json.load(f)
with open("regions_gangseo.json","r",encoding="utf-8") as f:
    regions = json.load(f)
with open("categories.json","r",encoding="utf-8") as f:
    categories = json.load(f)

# ì²˜ë¦¬ëœ ë™ë„¤ ê¸°ë¡ì„ ìœ„í•œ íŒŒì¼
PROGRESS_FILE = "crawling_progress.json"

def load_progress():
    """ì´ì „ì— ì²˜ë¦¬ëœ ë™ë„¤ ëª©ë¡ì„ ë¡œë“œ"""
    if os.path.exists(PROGRESS_FILE):
        with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
            return set(json.load(f))
    return set()

def save_progress(region_name):
    """ì²˜ë¦¬ëœ ë™ë„¤ë¥¼ ê¸°ë¡"""
    processed = load_progress()
    processed.add(region_name)
    with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(processed), f, ensure_ascii=False, indent=2)

class KarrotCrawler:
    def __init__(self, process_id):
        self.process_id = process_id
        # Chrome ì˜µì…˜ ì„¤ì •
        opts = uc.ChromeOptions()
        opts.add_argument('--no-sandbox')
        opts.add_argument('--disable-dev-shm-usage')
        opts.add_argument('--disable-blink-features=AutomationControlled')
        opts.add_argument('--disable-infobars')
        opts.add_argument('--disable-extensions')
        opts.add_argument('--start-maximized')
        opts.add_argument('--disable-gpu')
        opts.add_argument('--window-size=1920,1080')
        opts.add_argument('--ignore-certificate-errors')
        opts.add_argument('--allow-running-insecure-content')
        opts.add_argument('--disable-web-security')
        opts.add_argument('--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        # ì¶”ê°€ ì˜µì…˜
        opts.add_argument('--disable-popup-blocking')
        opts.add_argument('--disable-notifications')
        opts.add_argument('--disable-default-apps')
        opts.add_argument('--disable-save-password-bubble')
        opts.add_argument('--disable-translate')
        opts.add_argument('--disable-features=IsolateOrigins,site-per-process')
        
        # ìºì‹œ ë° ì¿ í‚¤ ì´ˆê¸°í™” ì˜µì…˜ ì¶”ê°€
        opts.add_argument('--incognito')  # ì‹œí¬ë¦¿ ëª¨ë“œ
        opts.add_argument('--disable-application-cache')
        opts.add_argument('--disable-cache')
        opts.add_argument('--disable-offline-load-stale-cache')
        opts.add_argument('--disk-cache-size=0')
        
        # í”„ë¡œì„¸ìŠ¤ë³„ ê³ ìœ í•œ ì‚¬ìš©ì ë°ì´í„° ë””ë ‰í† ë¦¬ ì„¤ì •
        opts.add_argument(f'--user-data-dir=./chrome_data_{process_id}')
        
        # ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹œë„
        max_retries = 3
        for attempt in range(max_retries):
            try:
                # ê¸°ì¡´ ë“œë¼ì´ë²„ê°€ ìˆë‹¤ë©´ ì¢…ë£Œ
                try:
                    self.driver.quit()
                except:
                    pass
                
                print(f"ğŸ”„ í”„ë¡œì„¸ìŠ¤ {process_id}: Chrome ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹œë„ {attempt + 1}/{max_retries}")
                
                # ìƒˆë¡œìš´ ë“œë¼ì´ë²„ ìƒì„±
                self.driver = uc.Chrome(options=opts)
                self.wait = WebDriverWait(self.driver, 15)
                
                # ì¿ í‚¤ ë° ìºì‹œ ì‚­ì œ
                self.driver.delete_all_cookies()
                
                # ë¨¼ì € ë‹¹ê·¼ë§ˆì¼“ ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™
                print(f"ğŸŒ í”„ë¡œì„¸ìŠ¤ {process_id}: ë‹¹ê·¼ë§ˆì¼“ ë©”ì¸ í˜ì´ì§€ë¡œ ì´ë™ ì‹œë„...")
                self.driver.get("https://www.daangn.com")
                time.sleep(5)
                
                # ë©”ì¸ í˜ì´ì§€ê°€ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
                try:
                    self.wait.until(
                        EC.presence_of_element_located((By.CSS_SELECTOR, 'button[data-gtm="gnb_location"]'))
                    )
                    print(f"âœ… í”„ë¡œì„¸ìŠ¤ {process_id}: ë‹¹ê·¼ë§ˆì¼“ ë©”ì¸ í˜ì´ì§€ ë¡œë“œ ì„±ê³µ")
                    return
                        
                except Exception as e:
                    print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {process_id}: í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                    if attempt < max_retries - 1:
                        print(f"ğŸ”„ í”„ë¡œì„¸ìŠ¤ {process_id}: ì¬ì‹œë„...")
                        time.sleep(5)
                        continue
                    raise Exception("í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨")
                    
            except Exception as e:
                print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {process_id}: ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(5)
                    continue
                raise Exception("ë“œë¼ì´ë²„ ì´ˆê¸°í™” ì‹¤íŒ¨")

    def safe_get(self, url, max_retries=3):
        """ì•ˆì „í•˜ê²Œ í˜ì´ì§€ ë¡œë“œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
        for attempt in range(max_retries):
            try:
                # í˜„ì¬ URL í™•ì¸
                current_url = self.driver.current_url
                if current_url != url:
                    self.driver.get(url)
                    time.sleep(5)
                
                # í˜ì´ì§€ê°€ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸
                self.wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
                return True
            except Exception as e:
                print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {self.process_id}: í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    # ë“œë¼ì´ë²„ ì¬ì´ˆê¸°í™” ì‹œë„
                    try:
                        self.driver.quit()
                    except:
                        pass
                    time.sleep(5)
                    self.__init__(self.process_id)  # ë“œë¼ì´ë²„ ì¬ì´ˆê¸°í™”
                    continue
                return False
        return False

    def process_category(self, region, cat):
        """í•œ ë™ë„¤ì—ì„œ í•œ ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§"""
        cat_name = cat["name"].replace("/", "-")  # ìŠ¬ë˜ì‹œë¥¼ í•˜ì´í”ˆìœ¼ë¡œ ë³€ê²½
        region_name = region["name"]
        # region["url"]ì—ì„œ in=... ë¶€ë¶„ë§Œ ì¶”ì¶œ (í•œê¸€)
        m = re.search(r"in=([^&]+)", region["url"])
        if m:
            region_in = m.group(1)
        else:
            region_in = ""
        # cat["url"]ì—ì„œ category_id ì¶”ì¶œ
        m2 = re.search(r"category_id=(\d+)", cat["url"])
        cat_id = m2.group(1) if m2 else "1"
        
        # ìƒˆë¡œìš´ URL í˜•ì‹ìœ¼ë¡œ ì¡°í•©
        full_url = f"https://www.daangn.com/kr/buy-sell/?category_id={cat_id}&in={urllib.parse.quote(region_in)}"
        print(f"\nâ–¶ í”„ë¡œì„¸ìŠ¤ {self.process_id}: [{region_name}][{cat['name']}] í¬ë¡¤ë§ ì‹œì‘")
        
        # ì•ˆì „í•˜ê²Œ í˜ì´ì§€ ë¡œë“œ
        if not self.safe_get(full_url):
            print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {self.process_id}: [{region_name}][{cat['name']}] í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨, ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
            return

        # ë™ë„¤ë³„ í´ë” ìƒì„±
        os.makedirs(region_name, exist_ok=True)
        fn = f"daangn_{region_name}_{cat_name}.csv"
        with open(os.path.join(region_name, fn), "w", newline="", encoding="utf-8-sig") as f:
            w = csv.writer(f)
            w.writerow(["ì¹´í…Œê³ ë¦¬","ìƒí’ˆëª…","ê°€ê²©","ì‘ì„±ì¼ì","íŒë§¤ìƒíƒœ","URL"])
            f.flush()

            try:
                # (2) ìŠ¤í¬ë¡¤ + ë”ë³´ê¸° (ë²„íŠ¼ì´ ì—†ì„ ë•Œê¹Œì§€)
                more_click_count = 0
                while more_click_count < 5:  # ìµœëŒ€ 5íšŒë¡œ ì œí•œ
                    self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(1)
                    try:
                        btn = self.wait.until(EC.element_to_be_clickable(
                            (By.XPATH, "//button[contains(text(),'ë”ë³´ê¸°')]")
                        ))
                        self.driver.execute_script("arguments[0].scrollIntoView({block:'center'});", btn)
                        btn.click()
                        more_click_count += 1
                        print(f"     í”„ë¡œì„¸ìŠ¤ {self.process_id}: ë”ë³´ê¸° í´ë¦­ ({more_click_count}/5)")
                        time.sleep(1)
                    except:
                        print(f"     í”„ë¡œì„¸ìŠ¤ {self.process_id}: ë”ë³´ê¸° ë²„íŠ¼ ì—†ìŒ (ì´ {more_click_count}íšŒ í´ë¦­)")
                        break

                # (3) ëª¨ë“  ìƒí’ˆ ì¹´ë“œ ìˆ˜ì§‘
                cards = self.driver.find_elements(By.CSS_SELECTOR, 'a[data-gtm="search_article"]')
                print(f"   â–¶ í”„ë¡œì„¸ìŠ¤ {self.process_id}: [{cat['name']}] {len(cards)}ê°œ ìƒí’ˆ ë°œê²¬")
                
                for idx, card in enumerate(cards, 1):
                    try:
                        name  = card.find_element(By.CSS_SELECTOR, 'span.lm809sh').text.strip()
                        price = card.find_element(By.CSS_SELECTOR, 'span.lm809si').text.strip()
                        time_ = card.find_element(By.TAG_NAME, 'time').text.strip()
                        try:
                            status = card.find_element(By.CSS_SELECTOR,'span.mlbp660').text.strip()
                        except NoSuchElementException:
                            status = "íŒë§¤ì¤‘"
                        
                        w.writerow([cat["name"], name, price, time_, status, card.get_attribute("href")])
                        f.flush()
                        print(f"     í”„ë¡œì„¸ìŠ¤ {self.process_id}: {idx}/{len(cards)} [{status}] {name}")
                    except Exception as e:
                        print(f"     âš ï¸ í”„ë¡œì„¸ìŠ¤ {self.process_id}: {idx}ë²ˆì§¸ ìƒí’ˆ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
                        continue

                print(f"âœ… í”„ë¡œì„¸ìŠ¤ {self.process_id}: [{region_name}][{cat['name']}] â†’ {region_name}/{fn}")

            except Exception as e:
                print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {self.process_id}: [{region_name}][{cat['name']}] ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")

    def close(self):
        self.driver.quit()

def process_region(args):
    """í•œ ë™ë„¤ì˜ ëª¨ë“  ì¹´í…Œê³ ë¦¬ë¥¼ ì²˜ë¦¬í•˜ëŠ” í•¨ìˆ˜"""
    region, process_id = args
    region_name = region["name"]
    
    # ì´ë¯¸ ì²˜ë¦¬ëœ ë™ë„¤ì¸ì§€ í™•ì¸
    if region_name in load_progress():
        print(f"â­ï¸ í”„ë¡œì„¸ìŠ¤ {process_id}: {region_name}ì€(ëŠ”) ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ”„ í”„ë¡œì„¸ìŠ¤ {process_id}: {region_name} ì²˜ë¦¬ ì‹œì‘ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    crawler = KarrotCrawler(process_id)
    try:
        for cat in categories:
            crawler.process_category(region, cat)
        # ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ê°€ ì™„ë£Œë˜ë©´ ì§„í–‰ìƒí™© ì €ì¥
        save_progress(region_name)
        print(f"âœ… í”„ë¡œì„¸ìŠ¤ {process_id}: {region_name} ì²˜ë¦¬ ì™„ë£Œ - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    except Exception as e:
        print(f"âš ï¸ í”„ë¡œì„¸ìŠ¤ {process_id}: {region_name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    finally:
        crawler.close()

if __name__ == '__main__':
    # ì²˜ë¦¬í•  ë™ë„¤ ëª©ë¡ ì¶œë ¥
    print(f"\nğŸ“‹ ì²˜ë¦¬í•  ë™ë„¤ ëª©ë¡ ({len(regions)}ê°œ):")
    for region in regions:
        print(f"  - {region['name']}")
    
    # ì´ë¯¸ ì²˜ë¦¬ëœ ë™ë„¤ í™•ì¸
    processed = load_progress()
    if processed:
        print(f"\nâ­ï¸ ì´ë¯¸ ì²˜ë¦¬ëœ ë™ë„¤ ({len(processed)}ê°œ):")
        for name in processed:
            print(f"  - {name}")
    
    # ì²˜ë¦¬ë˜ì§€ ì•Šì€ ë™ë„¤ë§Œ í•„í„°ë§
    regions_to_process = [r for r in regions if r["name"] not in processed]
    print(f"\nğŸ”„ ì²˜ë¦¬í•  ë™ë„¤ ìˆ˜: {len(regions_to_process)}ê°œ")
    
    if not regions_to_process:
        print("\nâœ¨ ëª¨ë“  ë™ë„¤ê°€ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆìŠµë‹ˆë‹¤!")
        exit()
    
    # ê° í”„ë¡œì„¸ìŠ¤ì— ê³ ìœ  ID ë¶€ì—¬
    process_args = [(region, i) for i, region in enumerate(regions_to_process)]
    
    # ë³‘ë ¬ ì²˜ë¦¬
    num_processes = 4
    with Pool(num_processes) as pool:
        pool.map(process_region, process_args)
    
    print("\nğŸ‰ ëª¨ë“  ë™ë„¤Ã—ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì™„ë£Œ!") 