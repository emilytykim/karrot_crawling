import time, csv, os
import undetected_chromedriver as uc
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

# â”€â”€â”€ 1) ë“œë¼ì´ë²„ ì„¸íŒ… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
options = uc.ChromeOptions()
options.add_argument('--no-sandbox')
options.add_argument('--disable-dev-shm-usage')
driver = uc.Chrome(options=options)
wait = WebDriverWait(driver, 15)  # Increased timeout to 15 seconds

def safe_get_text(selector, timeout=5):
    """ì•ˆì „í•˜ê²Œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (íƒ€ì„ì•„ì›ƒ ì²˜ë¦¬)"""
    try:
        element = WebDriverWait(driver, timeout).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, selector))
        )
        return element.text.strip()
    except:
        return "N/A"

# â”€â”€â”€ 2) "ì†¡ë„ë™" í˜ì´ì§€ ì—´ê³  ì¹´í…Œê³ ë¦¬ë§Œ ì¶”ì¶œ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
try:
    driver.get("https://www.daangn.com/kr/buy-sell/?in=ì†¡ë„ë™-6543")
    time.sleep(2)

    # ì¹´í…Œê³ ë¦¬ ì„¹ì…˜ ì°¾ê¸°
    category_section = wait.until(
        EC.presence_of_element_located((By.XPATH, "//h3[text()='ì¹´í…Œê³ ë¦¬']/following-sibling::div"))
    )
    
    # ì¹´í…Œê³ ë¦¬ ë§í¬ ì¶”ì¶œ
    cats = category_section.find_elements(By.CSS_SELECTOR, 'a[data-gtm="search_filter"]')
    categories = []
    
    for a in cats:
        try:
            name = a.find_element(By.TAG_NAME, "span").text.strip()
            href = a.get_attribute("href")
            if name and href and "category_id" in href:  # ì‹¤ì œ ì¹´í…Œê³ ë¦¬ë§Œ í•„í„°ë§
                categories.append((name, href))
        except:
            continue

    print("â–¶ ì¹´í…Œê³ ë¦¬ ì¸ì‹:", [c[0] for c in categories])

    # â”€â”€â”€ 3) ì¹´í…Œê³ ë¦¬ë³„ í…ŒìŠ¤íŠ¸ ìˆœíšŒ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for cat_name, cat_url in categories:
        safe = cat_name.replace("/", "_").replace("\\", "_")
        fn = f"daangn_ì†¡ë„ë™_{safe}.csv"
        print(f"\nâ–¶ [{cat_name}] í…ŒìŠ¤íŠ¸ ì‹œì‘ â†’ {fn}")

        with open(fn, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            writer.writerow(["ì¹´í…Œê³ ë¦¬", "ìƒí’ˆëª…", "ê°€ê²©", "ë‹‰ë„¤ì„", "ì‘ì„±ì¼ì", "URL"])
            f.flush()

            try:
                driver.get(cat_url)
                time.sleep(2)

                # (2) ìŠ¤í¬ë¡¤ + ë”ë³´ê¸° (ìµœëŒ€ 5íšŒ)
                for _ in range(5):
                    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                    time.sleep(1)
                    try:
                        btn = wait.until(EC.element_to_be_clickable(
                            (By.XPATH, "//button[contains(text(),'ë”ë³´ê¸°')]")
                        ))
                        driver.execute_script("arguments[0].scrollIntoView({block:'center'});", btn)
                        btn.click()
                        time.sleep(1)
                    except:
                        break

                # (3) ìµœëŒ€ 5ê°œ ìƒí’ˆ ë§í¬ë§Œ
                anchors = driver.find_elements(By.CSS_SELECTOR, 'a[data-gtm="search_article"]')
                urls = []
                for a in anchors:
                    try:
                        href = a.get_attribute("href")
                        if href and "/kr/buy-sell/" in href and href not in urls:
                            urls.append(href)
                        if len(urls) >= 5:
                            break
                    except:
                        continue

                print(f"   â–¶ [{cat_name}] {len(urls)}ê°œ ë§í¬ ìˆ˜ì§‘ ì™„ë£Œ")

                # (4) ìƒì„¸ í¬ë¡¤ë§ + ì¦‰ì‹œ ì €ì¥
                for idx, url in enumerate(urls, 1):
                    try:
                        driver.get(url)
                        time.sleep(1)

                        title = safe_get_text("h1.sprinkles_display_inline_base__1byufe82a")
                        price = safe_get_text("h3.jy3q4ib.sprinkles_fontWeight_bold__1byufe81z")
                        nickname = safe_get_text("span._1mr23zje")
                        date = safe_get_text("time")

                        writer.writerow([cat_name, title, price, nickname, date, url])
                        f.flush()
                        print(f"     {idx}/{len(urls)} í¬ë¡¤ë§: {title}")

                    except Exception as e:
                        print(f"     âš ï¸ {idx}ë²ˆì§¸ ìƒí’ˆ í¬ë¡¤ë§ ì‹¤íŒ¨: {str(e)}")
                        continue

                print(f"âœ… [{cat_name}] í…ŒìŠ¤íŠ¸ CSV ìƒì„±ë¨ â†’ {os.path.abspath(fn)}")

            except Exception as e:
                print(f"âš ï¸ [{cat_name}] ì¹´í…Œê³ ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
                continue

except Exception as e:
    print(f"âš ï¸ ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")

finally:
    driver.quit()
    print("\nğŸ‰ ì¹´í…Œê³ ë¦¬ ìˆœíšŒ + í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
